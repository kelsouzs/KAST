# bin/2_featurization.py

"""
K-talysticFlow - Step 2: Data Featurization

This script converts molecules (represented by SMILES) from the training and
test datasets into numerical vectors, known as "fingerprints" or "features".
This process is essential for enabling the Deep Learning model to
"understand" the chemical structure.

Technology Used:
- ECFP (Extended-Connectivity Fingerprints), also known as
  Circular Fingerprints, via the DeepChem library.

Input:
- Training and test CSV files generated by script 01.
Output:
- Directories containing the featurized datasets in DeepChem format.
- A log file summarizing the process.
"""

import sys
import os
import warnings
import logging

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
warnings.filterwarnings('ignore', category=DeprecationWarning)
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

import tensorflow as tf
tf.get_logger().setLevel('ERROR')
logging.getLogger('deepchem').setLevel('ERROR')

import shutil
from datetime import datetime
import deepchem as dc

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

import settings as cfg
from utils import ensure_dir_exists


def setup_environment():
    from rdkit import RDLogger
    RDLogger.DisableLog('rdApp.*')
    
    if os.path.exists(cfg.FEATURIZED_DATA_DIR):
        shutil.rmtree(cfg.FEATURIZED_DATA_DIR)

    train_dir = os.path.join(cfg.FEATURIZED_DATA_DIR, 'train')
    test_dir = os.path.join(cfg.FEATURIZED_DATA_DIR, 'test')
    ensure_dir_exists(train_dir)
    ensure_dir_exists(test_dir)

    start_time = datetime.now()
    log_content = f"--- Featurization Log ---Started at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
    log_content += f"Using config: FP_SIZE={cfg.FP_SIZE}, FP_RADIUS={cfg.FP_RADIUS}\n\n"
    
    return train_dir, test_dir, log_content, start_time

def featurize_dataset(loader, input_path, output_dir, dataset_name):
    """Loads, featurizes, and saves a dataset with robust error handling."""
    print(f"\nProcessing and saving {dataset_name} dataset to: {output_dir}")
    if not os.path.exists(input_path):
        print(f"\n ⚠️ ERROR: Input file '{input_path}' not found.")
        return None, f" ⚠️ ERROR: Input file '{input_path}' not found.\n"
    
    try:
        rdkit_logger = logging.getLogger('rdkit')
        rdkit_logger.setLevel(logging.ERROR)
        
        dc_logger = logging.getLogger('deepchem')
        dc_logger.setLevel(logging.ERROR)
        
        from rdkit import RDLogger
        RDLogger.DisableLog('rdApp.*')
        
        print(f"\nStarting featurization of {dataset_name}... (this may take a few minutes)")
       
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            dataset = loader.create_dataset(input_path, data_dir=output_dir, shard_size=None)

        if dataset is None or len(dataset) == 0:
            error_msg = f" ⚠️ ERROR: Failed to featurize {dataset_name} dataset.\n"
            print(f"\n{error_msg}")
            return None, error_msg

        print(f"\n -> ✅ Successfully featurized {len(dataset)} molecules from {dataset_name}!")
        log_update = f"{dataset_name.capitalize()} dataset: {len(dataset)} molecules processed and saved to '{output_dir}'.\n"
        
        return dataset, log_update
        
    except Exception as e:
        error_msg = f"\n ⚠️ ERROR during featurization of {dataset_name}: {str(e)}\n"
        print(f"\n{error_msg}")
        return None, error_msg

def log_summary(log_content, train_dataset, test_dataset, duration):
    """Generates and saves the final log summarizing the process."""
    n_train = len(train_dataset) if train_dataset else 0
    n_test = len(test_dataset) if test_dataset else 0
    n_features = train_dataset.get_shape()[0][1] if train_dataset and n_train > 0 else 'N/A'

    summary = (
        f"\n----------------------- FEATURIZATION SUMMARY -----------------------\n"
        f"Training samples: {n_train}\n"
        f"Test samples: {n_test}\n"
        f"Number of features: {n_features}\n"
        f"Total duration: {str(duration).split('.')[0]}s\n"
        f"----------------------------- END OF LOG -----------------------------\n"
    )
    
    final_log_content = log_content + summary
    log_file_path = os.path.join(cfg.RESULTS_DIR, '02_featurization_log.txt')
    
    print("\n----------------------- SUMMARY ---------------------------")
    print(f"  Training samples: {n_train}")
    print(f"  Test samples: {n_test}")
    print(f"  Number of features: {n_features}")
    print(f"  Duration: {str(duration).split('.')[0]}s")
    print("----------------------------------------------------------")

    with open(log_file_path, 'w') as f:
        f.write(final_log_content)
    print(f"\nLog saved to: {log_file_path}")

def main():
    print("\n--- KAST | Step 2: Generating Fingerprints ---")
    
    train_dir, test_dir, log_content, start_time = setup_environment()
    
    featurizer = dc.feat.CircularFingerprint(size=cfg.FP_SIZE, radius=cfg.FP_RADIUS)
    loader = dc.data.CSVLoader(
        tasks=[cfg.LABEL_COL], feature_field=cfg.SMILES_COL, featurizer=featurizer
    )

    train_csv_path = os.path.join(cfg.RESULTS_DIR, cfg.OUTPUT_TRAIN_CSV)
    train_dataset, log_update = featurize_dataset(loader, train_csv_path, train_dir, "training")
    log_content += log_update
    if train_dataset is None:
        sys.exit(1)

    test_csv_path = os.path.join(cfg.RESULTS_DIR, cfg.OUTPUT_TEST_CSV)
    test_dataset, log_update = featurize_dataset(loader, test_csv_path, test_dir, "test")
    log_content += log_update
    if test_dataset is None:
        sys.exit(1)

    duration = datetime.now() - start_time
    log_summary(log_content, train_dataset, test_dataset, duration)

    print("\n✅ Fingerprints were generated successfully!")
    print("\n➡️     Next step: '[3] Training the Model'.")

if __name__ == '__main__':
    main()
